{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas-version: 2.2.0\n",
      "polars-version: 0.20.6\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import util\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(f\"pandas-version: {pd.__version__}\")\n",
    "print(f\"polars-version: {pl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_ORIGINS=\"/storage2/tbrekalo/HG002-simulated/chr19-read-origins.csv\"\n",
    "REF_MAP_PATH=\"/storage2/tbrekalo/HG002-simulated/chr19-ref.paf\"\n",
    "CHAINS_PATH=\"/home/tbrekalo/dev/tb-ram/dev-data/HG002/chr19-sim-sample-chain.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ovlps = util.load_paf_df(REF_MAP_PATH)\n",
    "df_chains = util.load_chains_df(CHAINS_PATH)\n",
    "df_origins = util.load_origins_df(READ_ORIGINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chain_ovlps = util.create_annotated_ref_overlaps_from_chains(\n",
    "    df_chains,\n",
    "    df_origins,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chain_ovlps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chains_detail = df_chains.join(\n",
    "    df_chain_ovlps.select(\n",
    "        \"chain-id\",\n",
    "        \"query-start\",\n",
    "        \"query-end\",\n",
    "        \"target-start\",\n",
    "        \"target-end\",\n",
    "        \"ratio\",\n",
    "    ),\n",
    "    on=\"chain-id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_chains_detail.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_chains_detail.group_by(\n",
    "    \"chain-id\",\n",
    "    maintain_order=True,\n",
    ").agg(\n",
    "    pl.col(\"query-match\").diff().min().alias(\"query-match-diff-min\"),\n",
    "    pl.col(\"query-match\").diff().mean().alias(\"query-match-diff-mean\"),\n",
    "    pl.col(\"query-match\").diff().median().alias(\"query-match-diff-median\"),\n",
    "    pl.col(\"query-match\").diff().max().alias(\"query-match-diff-max\"),\n",
    "\n",
    "    pl.col(\"query-length\").first(),\n",
    "    pl.col(\"query-start\").first(),\n",
    "    pl.col(\"query-end\").first(),\n",
    "    pl.col(\"query-matches\").first(),\n",
    "\n",
    "    (\n",
    "        pl.when(\n",
    "            pl.col(\"strand\") == \"+\"\n",
    "        ).then(\n",
    "            1\n",
    "        ).otherwise(\n",
    "            0\n",
    "        ).cast(pl.Int64)\n",
    "    ).first().alias(\"strand\"),\n",
    "\n",
    "    pl.col(\"chain-length\").first(),\n",
    "\n",
    "    pl.col(\"target-length\").first(),\n",
    "    pl.col(\"target-start\").first(),\n",
    "    pl.col(\"target-end\").first(),\n",
    "    pl.col(\"target-matches\").first(),\n",
    "\n",
    "    pl.col(\"ratio\").first(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_SETS = {\n",
    "    \"overlap\": [\n",
    "        \"strand\",\n",
    "        \"query-start\", \"query-end\", \"query-matches\",\n",
    "        \"target-start\", \"target-end\", \"target-matches\",\n",
    "    ],\n",
    "    \"matches\": [\n",
    "        \"strand\",\n",
    "        *[\n",
    "            f\"query-match-diff-{stat}\" for stat in [\n",
    "                \"min\", \"mean\", \"median\", \"max\",\n",
    "            ]\n",
    "        ],\n",
    "\n",
    "        \"query-start\", \"query-end\", \"query-matches\",\n",
    "        \"target-start\", \"target-end\", \"target-matches\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FEATURE_SETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTestData = namedtuple(\n",
    "    \"TrainTestData\", [\n",
    "        \"X_train\", \"X_test\", \"y_train\", \"y_test\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "def make_model_data(\n",
    "    df_features: pl.DataFrame,\n",
    "    feature_subset: list[str],\n",
    "    top_k: int = 4_000,\n",
    "    random_state: int = 42,\n",
    ") -> TrainTestData:\n",
    "    df_features = df_features.select(\n",
    "        *feature_subset, \n",
    "        \"ratio\",\n",
    "        (\n",
    "            pl.col(\"ratio\") >= 0.99\n",
    "        ).cast(pl.Int64).alias(\"label\")\n",
    "    ).top_k(\n",
    "        top_k,\n",
    "        by=\"ratio\",\n",
    "    )\n",
    "\n",
    "    X = df_features.select(*feature_subset).to_pandas()\n",
    "    Y = df_features.select(\"label\").to_pandas()\n",
    "    return TrainTestData(*train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=random_state,\n",
    "    ))\n",
    "    \n",
    "\n",
    "data = make_model_data(df_features, FEATURE_SETS[\"overlap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"logistic-regression\": LogisticRegression(),\n",
    "    \"std-svc\": make_pipeline(StandardScaler(), SVC(gamma=\"auto\")),\n",
    "    \"xgb-classifier\": xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        grow_policy=\"lossguide\",\n",
    "        random_state=42,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model.fit(data.X_train, data.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pl.DataFrame(schema={\"model\": str, \"class\": pl.Int64, \"metric\": str, \"value\": pl.Float64})\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(data.X_test)\n",
    "    report = metrics.classification_report(data.y_test, y_pred, output_dict=True)\n",
    "    df_report = pl.concat([\n",
    "        df_report,\n",
    "        pl.DataFrame(\n",
    "            pd.melt(\n",
    "                pd.DataFrame(report)[[\"0\", \"1\"]].transpose()[[\"precision\", \"recall\", \"f1-score\"]].reset_index(), \n",
    "                id_vars=[\"index\"],\n",
    "                var_name=\"metric\",\n",
    "            )[[\"index\", \"metric\", \"value\"]]\n",
    "        ).select(\n",
    "            pl.lit(name).alias(\"model\"),\n",
    "            pl.col(\"index\").alias(\"class\").cast(pl.Int64),\n",
    "            pl.col(\"metric\"),\n",
    "            pl.col(\"value\"),\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "g = sns.FacetGrid(df_report.to_pandas(), row=\"class\", col=\"metric\")\n",
    "g.map_dataframe(\n",
    "    sns.barplot, \n",
    "    x=\"model\",\n",
    "    y=\"value\",\n",
    "    hue=\"model\",\n",
    "    palette=\"deep\",\n",
    "    legend=True,\n",
    ").set(yscale = \"log\")\n",
    "\n",
    "g.set_xlabels()\n",
    "g.set_xticklabels([])\n",
    "\n",
    "min_val = np.round(df_report[\"value\"].min() - 0.01, 2)\n",
    "max_val = np.round(df_report[\"value\"].max() + 0.01, 2)\n",
    "g.set(\n",
    "    yticks=np.arange(min_val, max_val, 0.01),\n",
    "    yticklabels=[np.round(x, 2) for x in np.arange(min_val, max_val, 0.01)],\n",
    ")\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(models[\"xgb-classifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models[\"logistic-regression\"].intercept_)\n",
    "print(models[\"logistic-regression\"].coef_)\n",
    "\n",
    "print(models[\"logistic-regression\"].feature_names_in_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
